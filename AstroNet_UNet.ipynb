{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AstroNet-UNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLfiRwxEWrjx"
      },
      "source": [
        "First, clone the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvhanT9WXFm4",
        "outputId": "efee3261-89d7-4c98-8277-0dd8660f5a45"
      },
      "source": [
        "!git clone https://github.com/vairodp/AstroNet.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AstroNet'...\n",
            "remote: Enumerating objects: 837, done.\u001b[K\n",
            "remote: Counting objects: 100% (837/837), done.\u001b[K\n",
            "remote: Compressing objects: 100% (545/545), done.\u001b[K\n",
            "remote: Total 837 (delta 471), reused 604 (delta 261), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (837/837), 35.74 MiB | 19.62 MiB/s, done.\n",
            "Resolving deltas: 100% (471/471), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lKOx9bFXGYf",
        "outputId": "540d178d-3279-464f-eaa9-55f932fe80fb"
      },
      "source": [
        "%cd AstroNet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AstroNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYzSdYWnXNzz"
      },
      "source": [
        "Then install the missing libraries that our code requires:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06BNYpqcXR8S",
        "outputId": "07d58e58-cfb8-4b88-df26-3d6c56bb715e"
      },
      "source": [
        "!pip install tensorflow_addons\n",
        "!pip install tensorflow-datasets==4.3.0\n",
        "!pip install imgaug==0.4.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 501 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 512 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 532 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 542 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 563 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 573 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 593 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 604 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 634 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 665 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 686 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 696 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 716 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 737 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 747 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 768 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 778 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 788 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 808 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 819 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 829 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 839 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 849 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 860 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 870 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 890 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 921 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 952 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 962 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 983 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 993 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.0 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.0 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 11.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n",
            "Collecting tensorflow-datasets==4.3.0\n",
            "  Downloading tensorflow_datasets-4.3.0-py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (3.17.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (5.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.19.5)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (21.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (4.62.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (0.3.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (2.10)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets==4.3.0) (3.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.3.0) (1.53.0)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "Successfully installed tensorflow-datasets-4.3.0\n",
            "Collecting imgaug==0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (3.2.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (0.16.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (0.10.0)\n",
            "Installing collected packages: imgaug\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkL_UwcWXS0y"
      },
      "source": [
        "Make sure you're using a GPU in order to get fast train and inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrZuZRP-XgSl",
        "outputId": "31f3cdae-f6af-492f-93dc-01cef6b3e79a"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi4LyaHhXi3f"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thfdzLqFXq7k"
      },
      "source": [
        "Finally, run the training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrpL28zXbdal",
        "outputId": "6f58423b-e9ff-4a69-cd1d-b7144ed8ccc7"
      },
      "source": [
        "%cd src"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AstroNet/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YwH3nkcoNazB",
        "outputId": "8fb2e796-c77f-49d8-bbfc-531d592aa305"
      },
      "source": [
        "from unet import SourceSegmentation\n",
        "from datasets.convo_ska import ConvoSKA\n",
        "from callbacks.display_callback import DisplayCallback\n",
        "from configs.train_config import ITER_PER_EPOCH, NUM_EPOCHS\n",
        "\n",
        "\n",
        "# Set use_class_weights=False to run the model without weights for the 4 classes\n",
        "# Set tiny=True to run the smaller version of this model\n",
        "unet = SourceSegmentation((128,128,1), use_class_weights=True, tiny=False)\n",
        "unet.model.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.003, clipvalue=1.0)\n",
        "checkpoint_filepath = '../checkpoints/unet-best.h5'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='../log')\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "\n",
        "unet.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "dataset_train = ConvoSKA(mode='train').get_dataset()\n",
        "val_data = ConvoSKA(mode='validation').get_dataset()\n",
        "display_callback = DisplayCallback(val_data)\n",
        "\n",
        "\n",
        "unet.fit(dataset_train, epochs=NUM_EPOCHS, validation_data=val_data, \n",
        "        callbacks=[model_checkpoint_callback, display_callback, tensorboard_callback, early_stop_callback], steps_per_epoch=ITER_PER_EPOCH)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 128, 128, 64) 576         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 128, 64) 256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)         (None, 128, 128, 64) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 64) 36864       tf.nn.relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           tf.nn.relu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 128)  73728       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 128)  147456      tf.nn.relu_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0           tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  294912      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)       (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 256)  589824      tf.nn.relu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0           tf.nn.relu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 512)  1179648     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)       (None, 16, 16, 512)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 512)  2359296     tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)       (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)    0           tf.nn.relu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 1024)   4718592     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 1024)   4096        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_8 (TFOpLambda)       (None, 8, 8, 1024)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 1024)   9437184     tf.nn.relu_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 8, 1024)   4096        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_9 (TFOpLambda)       (None, 8, 8, 1024)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 16, 16, 512)  2097664     tf.nn.relu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16, 16, 1024) 0           conv2d_transpose[0][0]           \n",
            "                                                                 tf.nn.relu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  4718592     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_10 (TFOpLambda)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359296     tf.nn.relu_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_11 (TFOpLambda)      (None, 16, 16, 512)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      tf.nn.relu_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 tf.nn.relu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 256)  1179648     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_12 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 256)  589824      tf.nn.relu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_13 (TFOpLambda)      (None, 32, 32, 256)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      tf.nn.relu_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         \n",
            "                                                                 tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 128)  294912      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_14 (TFOpLambda)      (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 64, 128)  147456      tf.nn.relu_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_15 (TFOpLambda)      (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       tf.nn.relu_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 tf.nn.relu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 64) 73728       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_16 (TFOpLambda)      (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 128, 128, 64) 36864       tf.nn.relu_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_17 (TFOpLambda)      (None, 128, 128, 64) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 4)  260         tf.nn.relu_17[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 31,048,452\n",
            "Trainable params: 31,036,676\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            " 6/70 [=>............................] - ETA: 36s - loss: 0.0047 - accuracy: 0.4400WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1665s vs `on_train_batch_end` time: 0.2970s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1665s vs `on_train_batch_end` time: 0.2970s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/70 [=======>......................] - ETA: 23s - loss: 0.0025 - accuracy: 0.6539"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dae6c9d1239d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m unet.fit(dataset_train, epochs=NUM_EPOCHS, validation_data=val_data, \n\u001b[0;32m---> 28\u001b[0;31m         callbacks=[model_checkpoint_callback, display_callback, tensorboard_callback, early_stop_callback], steps_per_epoch=ITER_PER_EPOCH)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}